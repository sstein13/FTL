{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea237ef3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "('08001', '[08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]SQL Server does not exist or access denied. (17) (SQLDriverConnect); [08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionOpen (Connect()). (53)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_regression\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Connect to ODS Database\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m conn \u001b[38;5;241m=\u001b[39m pyodbc\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDRIVER=\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mSQL Server};SERVER=aahssdbods.amfam.com;DATABASE=OperationalDataStore;Trusted_Connection=yes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Global variable definitions\u001b[39;00m\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08001', '[08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]SQL Server does not exist or access denied. (17) (SQLDriverConnect); [08001] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionOpen (Connect()). (53)')"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import copy\n",
    "import holidays\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "# Connect to ODS Database\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=aahssdbods.amfam.com;DATABASE=OperationalDataStore;Trusted_Connection=yes')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "# Global variable definitions\n",
    "today = dt.date.today()\n",
    "current_year = str(dt.date.today())[:4]\n",
    "weekday_dict = {0:\"Monday\", 1:\"Tuesday\", 2:\"Wednesday\", 3:\"Thursday\", 4:\"Friday\", 5:\"Saturday\", 6:\"Sunday\"}\n",
    "moving_holidays = [\"New Year's Day\", \"Juneteenth National Independence Day\", \"Independence Day\", \"Veterans Day\", \"Christmas Day\"]\n",
    "static_holidays= [\"Martin Luther King Jr. Day\", \"Memorial Day\", \"Labor Day\", \"Columbus Day\", \"Thanksgiving\"]\n",
    "\n",
    "\n",
    "# Creates the dataframe from the Actual Volume excel file and cleans data\n",
    "volume_df = pd.read_excel(\"Actual Volume.xlsx\")\n",
    "volume_df.fillna(0, inplace = True)\n",
    "volume_df.rename(columns={\"# Service Level Calls Offered\":\"Date\", \"Unnamed: 1\":\"Start of Week\", \"Unnamed: 2\":\"Day of Week\", \"Department\":\"Advisor\", \"Unnamed: 4\":\"Agency\", \"Unnamed: 5\":\"Agency Helpline\", \"Unnamed: 6\":\"ASU\", \"Unnamed: 7\":\"ASU Set\", \"Unnamed: 8\":\"Claims Back Office\", \"Unnamed: 9\":\"Claims Hertz\", \"Unnamed: 10\":\"Claims Lead Line\", \"Unnamed: 11\":\"Claims Material Damage\", \"Unnamed: 12\":\"Claims Service Center\", \"Unnamed: 13\":\"Claims Team Lead\", \"Unnamed: 14\":\"Client Service\", \"Unnamed: 15\":\"Client Service Experts\", \"Unnamed: 16\":\"Client Service Set\", \"Unnamed: 17\":\"Sales\", \"Unnamed: 18\":\"Sales Experts\", \"Unnamed: 19\":\"Service Desk\", \"Unnamed: 20\":\"Underwriting\", \"Unnamed: 21\":\"Unite\", \"Unnamed: 22\":\"Unspecified\", \"Unnamed: 23\":\"Workforce\"}, inplace=True)\n",
    "volume_df.drop(index=0, inplace=True)\n",
    "     # Deletes columns for units that no longer exist or that we do not forecast for\n",
    "volume_df.drop([\"Advisor\", \"Agency Helpline\", \"ASU\", \"ASU Set\", \"Claims Back Office\", \"Claims Hertz\", \"Claims Lead Line\", \"Claims Material Damage\", \"Claims Service Center\", \"Claims Team Lead\", \"Client Service Set\", \"Service Desk\", \"Underwriting\", \"Unite\", \"Unspecified\", \"Workforce\"], axis = 1, inplace = True)\n",
    "     # Combines Sales and Service Experts, since they are forecasted as one unit\n",
    "volume_df[\"Experts\"] = volume_df[\"Sales Experts\"] + volume_df[\"Client Service Experts\"]\n",
    "volume_df.drop([\"Sales Experts\", \"Client Service Experts\"], axis = 1, inplace = True)\n",
    "    # Changes the Date column to objects instead of strings and adds a Year column\n",
    "volume_df[\"Date\"] = pd.to_datetime(volume_df.Date)\n",
    "volume_df[\"Year\"] = volume_df[\"Date\"].dt.strftime('%Y')\n",
    "\n",
    "\n",
    "# Creates the dataframe from the Define Matching Weeks excel file and cleans data\n",
    "define_matching_weeks_df = pd.read_excel(\"Define Matching Weeks.xlsx\")\n",
    "define_matching_weeks_df.fillna(\"none\", inplace = True)\n",
    "\n",
    "\n",
    "# Defines SQL queries\n",
    "cisco_sql = \"\"\"\n",
    "Select cti.DateTime, cti.PrecisionQueueID, cti.ODSDataSourceID, dpq.EnterpriseName, dpq.Dept_Name, CallsOfferedRouted + CallsRequeried as CallsOffered\n",
    "From AcqCiscoAW.Call_Type_SG_Interval cti\n",
    "left join ArcCiscoAW.V_CallDataCisco_Dim_Precision_Queue dpq\n",
    "\ton REPLACE(dpq.PrecisionQueueID, '~', '') = concat(cti.PrecisionQueueID, ODSDataSourceID)\n",
    "Where cast(cti.DateTime as time) > '07:00:01'\n",
    "And cast(cti.Datetime as time) < '21:59:59'\n",
    "And cti.DateTime > ?\n",
    "And cti.DateTime < ?\n",
    "\"\"\"\n",
    "\n",
    "cisco_year_sql = '''Select sum(CallsOfferedRouted + CallsRequeried) as CallsOffered\n",
    "  From AcqCiscoAW.Call_Type_SG_Interval cti\n",
    "  left join ArcCiscoAW.V_CallDataCisco_Dim_Precision_Queue dpq\n",
    "  on REPLACE(dpq.PrecisionQueueID, '~', '') = concat(cti.PrecisionQueueID, ODSDataSourceID)\n",
    "  Where cast(cti.DateTime as date) > '2018-02-28'\n",
    "  And cast(cti.DateTime as time) > '07:00:01'\n",
    "  And cast(cti.Datetime as time) < '21:59:59'\n",
    "  and datepart(year, cast(cti.Datetime as date)) = ?\n",
    "  And dpq.Dept_Name = ?\n",
    "  '''\n",
    "\n",
    "cisco_by_date_sql =\"\"\"\n",
    "Select cti.DateTime as Date, CallsOfferedRouted + CallsRequeried as CallsOffered\n",
    "From AcqCiscoAW.Call_Type_SG_Interval cti\n",
    "left join ArcCiscoAW.V_CallDataCisco_Dim_Precision_Queue dpq\n",
    "\ton REPLACE(dpq.PrecisionQueueID, '~', '') = concat(cti.PrecisionQueueID, ODSDataSourceID)\n",
    "Where cast(cti.DateTime as time) > '07:00:01'\n",
    "And cast(cti.Datetime as time) < '21:59:59'\n",
    "And cti.DateTime > '2018-02-28'\n",
    "And dpq.Dept_Name = ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead2a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_object(str_date):\n",
    "    \"\"\"\n",
    "    Returns the date as a datetime object when entered in mm/dd/yyyy format.\n",
    "    \"\"\"\n",
    "    month = str_date[:2]\n",
    "    day = str_date[3:5]\n",
    "    year = str_date[-4:]\n",
    "    \n",
    "    iso_date = year + '-' + month + '-' + day\n",
    "    \n",
    "    output = dt.date.fromisoformat(iso_date)\n",
    "    return output\n",
    "\n",
    "\n",
    "def object_to_str(object_date):\n",
    "    \"\"\"\n",
    "    Returns the date in mm/dd/yyyy format when entered as a datetime object.\n",
    "    \"\"\"\n",
    "    iso_date = dt.date.isoformat(object_date)\n",
    "    \n",
    "    month = iso_date[5:7]\n",
    "    day = iso_date[-2:]\n",
    "    year = iso_date[:4]\n",
    "    \n",
    "    output = month + \"/\" + day + \"/\" + year\n",
    "    return output\n",
    "\n",
    "\n",
    "def to_iso(date):\n",
    "    \"\"\"\n",
    "    Returns the date in iso format when entered in mm/dd/yyyy format.\n",
    "    \"\"\"\n",
    "    month = date[:2]\n",
    "    day = date[3:5]\n",
    "    year = date[-4:]\n",
    "    \n",
    "    iso_date = year + '-' + month + '-' + day\n",
    "    \n",
    "    return iso_date\n",
    "\n",
    "\n",
    "def start_of_week(date, week_offset=0):\n",
    "    \"\"\"\n",
    "    Returns the Start of Week for the date when entered in mm/dd/yyyy format. If a Sunday is entered, returns the Sunday \\\n",
    "    prior. Week offset is the number of weeks in the future (positive number) or past (negative number).\n",
    "    \"\"\"\n",
    "    if type(date) == str:\n",
    "        dt_date = str_to_object(date)\n",
    "    else:\n",
    "        dt_date = date\n",
    "        \n",
    "    sow_week_prior = 0\n",
    "    \n",
    "    if dt.date.weekday(dt_date) == 0:\n",
    "        sow_week_prior = dt_date + dt.timedelta(days=-1 + week_offset * 7)\n",
    "    elif dt.date.weekday(dt_date) == 1:\n",
    "        sow_week_prior = dt_date + dt.timedelta(days=-2 + week_offset * 7)\n",
    "    elif dt.date.weekday(dt_date) == 2:\n",
    "        sow_week_prior = dt_date + dt.timedelta(days=-3 + week_offset * 7)\n",
    "    elif dt.date.weekday(dt_date) == 3:\n",
    "        sow_week_prior = dt_date + dt.timedelta(days=-4 + week_offset * 7)\n",
    "    elif dt.date.weekday(dt_date) == 4:\n",
    "        sow_week_prior = dt_date + dt.timedelta(days=-5 + week_offset * 7)\n",
    "    elif dt.date.weekday(dt_date) == 5:\n",
    "        sow_week_prior = dt_date + dt.timedelta(days=-6 + week_offset * 7)\n",
    "    elif dt.date.weekday(dt_date) == 6:\n",
    "        sow_week_prior = dt_date + dt.timedelta(days=-7 + week_offset * 7)\n",
    "        \n",
    "    output = object_to_str(sow_week_prior)\n",
    "    return output\n",
    "\n",
    "\n",
    "def day_volume(date, unit):\n",
    "    \"\"\"Retrieves a single day's volume for a unit. Date must be in mm/dd/yyyy format.\"\"\"\n",
    "    \n",
    "    date = str_to_object(date)\n",
    "    \n",
    "    if date >= dt.date(2023, 1, 1):\n",
    "        if unit == \"Experts\":\n",
    "            return day_volume(object_to_str(date), \"Sales Experts\") + day_volume(object_to_str(date), \"Client Service Experts\")\n",
    "        date = to_iso(object_to_str(date))\n",
    "        cursor.execute(cisco_sql, date + ' 07:00:01', date + ' 21:59:59')\n",
    "        term_list = cursor.fetchall()\n",
    "        df = pd.DataFrame.from_records(term_list, columns=[col[0] for col in cursor.description])\n",
    "        return int(df.loc[df[\"Dept_Name\"] == unit, \"CallsOffered\"].sum())\n",
    "    else:\n",
    "        temp_df1 = volume_df.loc[volume_df[\"Date\"] == to_iso(object_to_str(date))]\n",
    "        return temp_df1[unit].sum()\n",
    "    \n",
    "\n",
    "def week_volume(start_of_week, unit):\n",
    "    \"\"\"Given a Sunday in mm/dd/yyyy format, retreives volume for that week in dictionary format.\"\"\"\n",
    "    start_of_week = str_to_object(start_of_week)\n",
    "    volume_dict = {}\n",
    "    for dow in range(7):\n",
    "        volume = day_volume(object_to_str(start_of_week + pd.Timedelta(days=1 + dow)), unit)\n",
    "        if volume == 0:\n",
    "            continue\n",
    "        volume_dict[object_to_str(start_of_week + pd.Timedelta(days=1 + dow))] = volume\n",
    "    return volume_dict\n",
    "\n",
    "\n",
    "def dataframe(unit):\n",
    "    \"\"\"Returns a dataframe with all daily volume data for a unit.\"\"\"\n",
    "    \n",
    "    cursor.execute(cisco_by_date_sql, unit)\n",
    "    term_list = cursor.fetchall()\n",
    "    df = pd.DataFrame.from_records(term_list, columns=[col[0] for col in cursor.description])\n",
    "    df[\"Date\"] = df[\"Date\"].dt.date\n",
    "    df = df.groupby([\"Date\"], as_index=False).sum()\n",
    "    df.rename(columns={\"Date\": \"ds\", \"CallsOffered\": \"y\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def total_volume_in_range(start_date, end_date, unit):\n",
    "    \"\"\"Given start and end dates in mm/dd/yyyy format, returns total volume in that range. (end date excluded) (currently only works for dates after 3/1/2018)\"\"\"\n",
    "    if unit == \"Experts\":\n",
    "        return total_volume_in_range(start_date, end_date, \"Sales Experts\") + total_volume_in_range(start_date, end_date, \"Client Service Experts\")\n",
    "    \n",
    "    start_date = to_iso(start_date)\n",
    "    end_date = to_iso(end_date)\n",
    "    cursor.execute(cisco_sql, start_date + ' 00:00:00', end_date + ' 00:00:00')\n",
    "    term_list = cursor.fetchall()\n",
    "    df = pd.DataFrame.from_records(term_list, columns=[col[0] for col in cursor.description])\n",
    "    return int(df.loc[df[\"Dept_Name\"] == unit, \"CallsOffered\"].sum())\n",
    "\n",
    "\n",
    "def yearly_volume(year, unit):\n",
    "  \"\"\"Given a year entered as an interval, returns the total volume for that year.\"\"\"\n",
    "\n",
    "  if year <= 2023:\n",
    "      temp_df1 = volume_df.loc[volume_df[\"Year\"] == str(year)]\n",
    "      return temp_df1[unit].sum()\n",
    "  else:\n",
    "    cursor.execute(cisco_year_sql, str(year), unit)\n",
    "    term_list = cursor.fetchall()\n",
    "    df = pd.DataFrame.from_records(term_list, columns=[col[0] for col in cursor.description])\n",
    "    return df.CallsOffered.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70abf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_1(unit, start_date=start_of_week((object_to_str(today)),1)):\n",
    "    \"\"\"\n",
    "    Returns the total volume forecasted for the given unit for next week using method 1, forecasting yearly volume using the last 4 weeks method.\n",
    "    \"\"\"\n",
    "    print(\"Running Method 1 for week of \" + start_date)\n",
    "\n",
    "    yearly_volume_dict = {} #Dictionary of each year's total volume\n",
    "    working_matching_weeks_list = []  #Lists the start_date and the start of all matching weeks for prior years\n",
    "    current_matching_weeks_list = [] #Lists the start of last week and all matching weeks for prior years (used for year_output when start_date is in the future)\n",
    "    matching_weeks_total_dict = {} #Dictionary of the total volume for the matching weeks of each year\n",
    "    matching_weeks_per_dict = {} #Dictionary of the percent of total year volume for the matching weeks of each year\n",
    "    dow_per_dict = {} #Dictionary of the dow % for each day of week for the matching weeks of each year\n",
    "    last_4_matching_weeks_total_dict = {} #Dictionary of the total volume for the prior 4 matching weeks of each year\n",
    "    last_4_matching_weeks_per_dict = {} #Dictionary of the percent of total year volume in the prior 4 matching weeks of each year\n",
    "    past_years_holiday_dow = {} #When there is a moving holiday, dictionary of the dow that holiday fell on each year\n",
    "\n",
    "    working_year = start_date[-4:]\n",
    "    \n",
    "\n",
    "    ### IDENTIFYING HOLIDAY ###\n",
    "    week_df = define_matching_weeks_df[define_matching_weeks_df.isin([start_date]).any(axis=1)]\n",
    "    if week_df['Holiday'].isin(moving_holidays).any():\n",
    "        holiday = \"Moving Holiday\"\n",
    "    elif week_df['Holiday'].isin(static_holidays).any():\n",
    "        holiday = \"Static Holiday\"\n",
    "    else:\n",
    "        holiday = \"No Holiday\"\n",
    "        \n",
    "\n",
    "    ### FILLING OUT LISTS AND DICTS ###\n",
    "    for year in range(2012, int(object_to_str(today)[-4:])+1):\n",
    "        yearly_volume_dict[year] = yearly_volume(year, unit)\n",
    "\n",
    "    working_week_matching_weeks_df = define_matching_weeks_df.copy()\n",
    "    for i in range(int((len(define_matching_weeks_df.columns) + 1)/2)):\n",
    "        working_week_matching_weeks_df.pop(working_week_matching_weeks_df.columns.values[0])\n",
    "    working_row = working_week_matching_weeks_df.index[working_week_matching_weeks_df[working_year + \" Date\"] == start_date][0]\n",
    "    working_matching_weeks_list = working_week_matching_weeks_df.values[working_row].tolist()\n",
    "\n",
    "    current_week_matching_weeks_df = define_matching_weeks_df.copy()\n",
    "    for i in range(int((len(define_matching_weeks_df.columns) + 1)/2)):\n",
    "        current_week_matching_weeks_df.pop(current_week_matching_weeks_df.columns.values[0])\n",
    "    current_row = current_week_matching_weeks_df.index[current_week_matching_weeks_df[current_year + \" Date\"] == start_of_week((object_to_str(today)),1)][0]\n",
    "    current_matching_weeks_list = current_week_matching_weeks_df.values[current_row].tolist()\n",
    "\n",
    "    if start_date < start_of_week(object_to_str(today)):\n",
    "        for start in working_matching_weeks_list:\n",
    "            year_current = start[-4:]\n",
    "            last_4_matching_weeks_total_dict[year_current] = {start_of_week(start,-1): sum(week_volume(start_of_week(start,-1), unit).values()),\n",
    "            start_of_week(start,-2): sum(week_volume(start_of_week(start,-2), unit).values()), \n",
    "            start_of_week(start,-3): sum(week_volume(start_of_week(start,-3), unit).values()),\n",
    "            start_of_week(start,-4): sum(week_volume(start_of_week(start,-4), unit).values())}\n",
    "    else:\n",
    "        for start in current_matching_weeks_list:\n",
    "            year_current = start[-4:]\n",
    "            last_4_matching_weeks_total_dict[year_current] = {start_of_week(start,-1): sum(week_volume(start_of_week(start,-1), unit).values()),\n",
    "            start_of_week(start,-2): sum(week_volume(start_of_week(start,-2), unit).values()), \n",
    "            start_of_week(start,-3): sum(week_volume(start_of_week(start,-3), unit).values()),\n",
    "            start_of_week(start,-4): sum(week_volume(start_of_week(start,-4), unit).values())}\n",
    "\n",
    "    for year in last_4_matching_weeks_total_dict:\n",
    "        year_int = int(year)\n",
    "        if yearly_volume_dict[year_int] == 0:\n",
    "            continue\n",
    "        last_4_matching_weeks_per_dict[year] = sum(last_4_matching_weeks_total_dict[year].values()) / yearly_volume_dict[year_int]\n",
    "\n",
    "    for start in working_matching_weeks_list:\n",
    "        year_working = start[-4:]\n",
    "        matching_weeks_total_dict[year_working] = sum(week_volume(start_of_week(start, 1), unit).values())\n",
    "\n",
    "    for year in matching_weeks_total_dict:\n",
    "        if int(year) not in yearly_volume_dict:\n",
    "            continue\n",
    "        elif yearly_volume_dict[int(year)] == 0:\n",
    "            continue\n",
    "        year_int = int(year)\n",
    "        matching_weeks_per_dict[year] = matching_weeks_total_dict[year] / yearly_volume_dict[year_int]\n",
    "\n",
    "    for start in working_matching_weeks_list:\n",
    "        year_current = start[-4:]\n",
    "        if int(year_current) >= int(working_year):\n",
    "            continue\n",
    "        if year_current not in matching_weeks_total_dict or matching_weeks_total_dict[year_current] == 0:\n",
    "            continue\n",
    "        if year_current not in dow_per_dict:\n",
    "            dow_per_dict[year_current] = {}\n",
    "        for dow in range(0, 7):\n",
    "            date_current = object_to_str(str_to_object(start) + dt.timedelta(days=dow + 1))\n",
    "            dow_current = weekday_dict[dow]\n",
    "            dow_per_dict[year_current][dow_current] = day_volume(date_current, unit) / matching_weeks_total_dict[year_current]\n",
    "\n",
    "       \n",
    "    ### DELETING KEYS IN DICTS WHERE THE VALUE IS 0 ###\n",
    "\n",
    "    for year in list(yearly_volume_dict):\n",
    "        if yearly_volume_dict[year] == 0:\n",
    "            del yearly_volume_dict[year]\n",
    "            \n",
    "    for year in list(matching_weeks_total_dict):\n",
    "        if matching_weeks_total_dict[year] == 0:\n",
    "            del matching_weeks_total_dict[year]\n",
    "\n",
    "\n",
    "      \n",
    "    ### REMOVING OUTLIERS AND CALCULATING END VALUES ###\n",
    "    outliers_excluded = 0\n",
    "\n",
    "    count_last_4_per = 0\n",
    "    total_last_4_per = 0\n",
    "    year_per_values = []\n",
    "    for year in last_4_matching_weeks_per_dict:\n",
    "        year_per_values.append(list(last_4_matching_weeks_per_dict.values()))\n",
    "    year_per_Q1 = np.percentile(year_per_values, 25)\n",
    "    year_per_Q3 = np.percentile(year_per_values, 75)\n",
    "    year_per_IQR = year_per_Q3 - year_per_Q1\n",
    "    year_per_upper = year_per_Q3 + 1.5 * year_per_IQR\n",
    "    year_per_lower = year_per_Q1 - 1.5 * year_per_IQR\n",
    "    for year in list(last_4_matching_weeks_per_dict):\n",
    "        if last_4_matching_weeks_per_dict[year] >= year_per_upper:\n",
    "            del last_4_matching_weeks_per_dict[year]\n",
    "            outliers_excluded += 1\n",
    "        elif last_4_matching_weeks_per_dict[year] <= year_per_lower:\n",
    "            del last_4_matching_weeks_per_dict[year]\n",
    "            outliers_excluded += 1\n",
    "    for year in last_4_matching_weeks_per_dict:\n",
    "        if int(year) >= int(working_year):\n",
    "            continue\n",
    "        count_last_4_per += 1\n",
    "        total_last_4_per += last_4_matching_weeks_per_dict[year]\n",
    "    avg_per_last_4 = total_last_4_per / count_last_4_per\n",
    "    last_4_current_year_total = 0\n",
    "    for year in last_4_matching_weeks_total_dict:\n",
    "        if year == working_year:\n",
    "            for start in last_4_matching_weeks_total_dict[year]:\n",
    "                last_4_current_year_total += last_4_matching_weeks_total_dict[year][start]\n",
    "    year_output = round((1 / avg_per_last_4) * last_4_current_year_total)\n",
    "        \n",
    "    if holiday == \"Moving Holiday\":\n",
    "        holiday_name = week_df['Holiday'].item()\n",
    "        for date, name in sorted(holidays.US(years=int(start[-4:])).items()):\n",
    "            if name == holiday_name:\n",
    "                holiday_date = date\n",
    "            else:\n",
    "                continue\n",
    "        for year in matching_weeks_total_dict:\n",
    "            past_years_holiday_dow[year] = str_to_object(object_to_str(holiday_date)[:-4]+year).weekday()\n",
    "        for year in past_years_holiday_dow:\n",
    "            if past_years_holiday_dow[year] != holiday_date.weekday():\n",
    "                del matching_weeks_per_dict[year]\n",
    "    \n",
    "    total_woy_per = 0\n",
    "    count_woy_per = 0\n",
    "    woy_values = []\n",
    "    for year in matching_weeks_per_dict:\n",
    "        woy_values.append(list(matching_weeks_per_dict.values()))\n",
    "    woy_Q1 = np.percentile(woy_values, 25)\n",
    "    woy_Q3 = np.percentile(woy_values, 75)\n",
    "    woy_IQR = woy_Q3 - woy_Q1\n",
    "    woy_upper = woy_Q3 + 1.5 * woy_IQR\n",
    "    woy_lower = woy_Q1 - 1.5 * woy_IQR\n",
    "    for year in list(matching_weeks_per_dict):\n",
    "        if matching_weeks_per_dict[year] >= woy_upper:\n",
    "            del matching_weeks_per_dict[year]\n",
    "            outliers_excluded += 1\n",
    "        elif matching_weeks_per_dict[year] <= woy_lower:\n",
    "            del matching_weeks_per_dict[year]\n",
    "            outliers_excluded += 1\n",
    "    for year in matching_weeks_per_dict:\n",
    "        if int(year) >= int(working_year):\n",
    "            continue\n",
    "        else:\n",
    "            total_woy_per += matching_weeks_per_dict[year]\n",
    "            count_woy_per += 1\n",
    "    avg_woy_per = total_woy_per / count_woy_per\n",
    "    woy_output = round(avg_woy_per * year_output)\n",
    "    \n",
    "\n",
    "    dow_buckets = {}\n",
    "    for year in dow_per_dict:\n",
    "        for dow in dow_per_dict[year]:\n",
    "            if dow not in dow_buckets:\n",
    "                dow_buckets[dow] = {}\n",
    "            dow_buckets[dow][year] = dow_per_dict[year][dow]\n",
    "\n",
    "\n",
    "    for dow in dow_buckets:\n",
    "        dow_values = []\n",
    "        for year in dow_buckets[dow]:\n",
    "            dow_values.append(list(dow_buckets[dow].values()))\n",
    "\n",
    "        dow_Q1 = np.percentile(dow_values, 25)\n",
    "        dow_Q3 = np.percentile(dow_values, 75)\n",
    "        dow_IQR = dow_Q3 - dow_Q1\n",
    "        dow_upper = dow_Q3 + 1.5 * dow_IQR\n",
    "        dow_lower = dow_Q1 - 1.5 * dow_IQR\n",
    "\n",
    "        for year in list(dow_per_dict):\n",
    "            for dow2 in list(dow_per_dict[year]):\n",
    "                if dow2 == dow and dow_per_dict[year][dow] >= dow_upper:\n",
    "                    del dow_per_dict[year][dow]\n",
    "                    outliers_excluded += 1\n",
    "                elif dow2 == dow and dow_per_dict[year][dow] <= dow_lower:\n",
    "                    del dow_per_dict[year][dow]\n",
    "                    outliers_excluded += 1\n",
    "                    \n",
    "    if holiday == \"Moving Holiday\":\n",
    "        holiday_name = week_df['Holiday'].item()\n",
    "        for date, name in sorted(holidays.US(years=int(start[-4:])).items()):\n",
    "            if name == holiday_name:\n",
    "                holiday_date = date\n",
    "            else:\n",
    "                continue\n",
    "        for year in matching_weeks_total_dict:\n",
    "            past_years_holiday_dow[year] = str_to_object(object_to_str(holiday_date)[:-4]+year).weekday()\n",
    "        for year in past_years_holiday_dow:\n",
    "            if past_years_holiday_dow[year] != holiday_date.weekday():\n",
    "                del dow_per_dict[year]\n",
    "    \n",
    "    avg_dow_per = {\"Monday\": 0, \"Tuesday\": 0, \"Wednesday\": 0, \"Thursday\": 0, \"Friday\": 0, \"Saturday\": 0, \"Sunday\": 0}\n",
    "    \n",
    "    for dow in avg_dow_per.keys():\n",
    "        count_dow_per = 0\n",
    "        total_dow_per = 0\n",
    "        for year in dow_per_dict:\n",
    "            for dow2 in dow_per_dict[year]:\n",
    "                if dow2 == dow:\n",
    "                    total_dow_per += dow_per_dict[year][dow]\n",
    "                    count_dow_per += 1\n",
    "        if count_dow_per == 0:\n",
    "            avg_dow_per[dow] = 0\n",
    "        else:\n",
    "            avg_dow_per[dow] = total_dow_per / count_dow_per\n",
    "            \n",
    "    dow_output = {}\n",
    "    \n",
    "    for dow in avg_dow_per.keys():\n",
    "        if avg_dow_per[dow] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            dow_output[dow] = round(woy_output * avg_dow_per[dow])\n",
    "            \n",
    "\n",
    "    return {\"start_date\": start_date, \"unit\": unit, \"forecast\": dow_output, \"outliers_excluded\": outliers_excluded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e50fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_2(unit, start_date=start_of_week((object_to_str(today)),1)):\n",
    "    \"\"\"\n",
    "    Returns the total volume forecasted for the given unit for next week using method 2.\n",
    "    \"\"\"\n",
    "    print(\"Running Method 2 for week of \" + start_date)\n",
    "\n",
    "    week_to_compare_historical_volume = {} #Dictionary of total volume for each prior year matching the comparison week.\n",
    "    working_week_historical_volume = {} #Dictionary of total volume for each prior year matching the forecast week.\n",
    "    dow_per_dict = {} #Dictionary of the dow % for each day of week for the matching weeks of each year.\n",
    "    wow_list = [] #List of % change between prior years' comparison and working weeks.\n",
    "    past_years_holiday_dow = {} #When there is a moving holiday, dictionary of the dow that holiday fell on each year\n",
    "\n",
    "    \n",
    "    working_year = start_date[-4:]\n",
    "    \n",
    "    \n",
    "    if start_date < start_of_week((object_to_str(today)),1):\n",
    "        week_to_compare = start_of_week(start_date, -1)\n",
    "    else:\n",
    "        week_to_compare = start_of_week(object_to_str(today), -1)\n",
    "        \n",
    "    comparison_year = week_to_compare[-4:]\n",
    "          \n",
    "    comparison_week_matching_weeks_df = define_matching_weeks_df.copy()\n",
    "    for i in range(int((len(define_matching_weeks_df.columns) + 1)/2)):\n",
    "        comparison_week_matching_weeks_df.pop(comparison_week_matching_weeks_df.columns.values[0])\n",
    "    comparison_row = comparison_week_matching_weeks_df.index[comparison_week_matching_weeks_df[comparison_year + \" Date\"] == week_to_compare][0]\n",
    "    comparison_weeks = comparison_week_matching_weeks_df.values[comparison_row].tolist()\n",
    "    for week in list(comparison_weeks):\n",
    "        if int(week[-4:]) >= int(comparison_year):\n",
    "            comparison_weeks.remove(week)\n",
    "            \n",
    "    working_week_matching_weeks_df = define_matching_weeks_df.copy()\n",
    "    for i in range(int((len(define_matching_weeks_df.columns) + 1)/2)):\n",
    "        working_week_matching_weeks_df.pop(working_week_matching_weeks_df.columns.values[0])\n",
    "    working_row = working_week_matching_weeks_df.index[working_week_matching_weeks_df[working_year + \" Date\"] == start_date][0]\n",
    "    working_weeks = working_week_matching_weeks_df.values[working_row].tolist()\n",
    "    for week in list(working_weeks):\n",
    "        if int(week[-4:]) >= int(working_year):\n",
    "            working_weeks.remove(week)\n",
    "            \n",
    "    \n",
    "    ### IDENTIFYING HOLIDAY ###\n",
    "    week_df = define_matching_weeks_df[define_matching_weeks_df.isin([start_date]).any(axis=1)]\n",
    "    if week_df['Holiday'].isin(moving_holidays).any():\n",
    "        holiday = \"Moving Holiday\"\n",
    "    elif week_df['Holiday'].isin(static_holidays).any():\n",
    "        holiday = \"Static Holiday\"\n",
    "    else:\n",
    "        holiday = \"No Holiday\"\n",
    "   \n",
    "\n",
    "   ### FILLING OUT LISTS AND DICTS ###  \n",
    "    for week in comparison_weeks:\n",
    "        week_to_compare_historical_volume[week] = sum(week_volume(week, unit).values())\n",
    "    \n",
    "    for week in working_weeks:\n",
    "        working_week_historical_volume[week] = sum(week_volume(week, unit).values()) \n",
    "        \n",
    "    if holiday == \"Moving Holiday\":\n",
    "        holiday_name = week_df['Holiday'].item()\n",
    "        for date, name in sorted(holidays.US(years=int(working_year)).items()):\n",
    "            if name == holiday_name:\n",
    "                holiday_date = date\n",
    "            else:\n",
    "                continue\n",
    "        for start in working_week_historical_volume:\n",
    "            past_years_holiday_dow[start] = str_to_object(object_to_str(holiday_date)[:-4]+start[-4:]).weekday()\n",
    "        for start in past_years_holiday_dow:\n",
    "            if past_years_holiday_dow[start] != holiday_date.weekday():\n",
    "                del working_week_historical_volume[start]\n",
    "\n",
    "    for start in working_weeks:\n",
    "        year_current = start[-4:]\n",
    "        if int(year_current) >= int(working_year):\n",
    "            continue\n",
    "        if start not in working_week_historical_volume or working_week_historical_volume[start] == 0:\n",
    "            continue\n",
    "        if year_current not in dow_per_dict:\n",
    "            dow_per_dict[year_current] = {}\n",
    "        for dow in range(0, 7):\n",
    "            date_current = object_to_str(str_to_object(start) + dt.timedelta(days=dow + 1))\n",
    "            dow_current = weekday_dict[dow]\n",
    "            dow_per_dict[year_current][dow_current] = day_volume(date_current, unit) / working_week_historical_volume[start]  \n",
    "    \n",
    "    week_prior_total_volume = sum(week_volume(week_to_compare, unit).values())\n",
    "                        \n",
    "    for start in list(week_to_compare_historical_volume):\n",
    "        if week_to_compare_historical_volume[start] == 0:\n",
    "            del week_to_compare_historical_volume[start]\n",
    "\n",
    "    for start in working_week_historical_volume:\n",
    "        temp_working_year = start[-4:]\n",
    "        for start2 in week_to_compare_historical_volume:\n",
    "            temp_comparison_year = start2[-4:]\n",
    "            if temp_comparison_year == temp_working_year:\n",
    "                wow_list.append(working_week_historical_volume[start] / week_to_compare_historical_volume[start2])\n",
    "    \n",
    "\n",
    "    ### REMOVING OUTLIERS AND CALCULATING END VALUES ###\n",
    "    outliers_excluded = 0\n",
    "\n",
    "    if holiday != \"Moving Holiday\":\n",
    "        wow_Q1 = np.percentile(wow_list, 25)\n",
    "        wow_Q3 = np.percentile(wow_list, 75)\n",
    "        wow_IQR = wow_Q3 - wow_Q1\n",
    "        wow_upper = wow_Q3 + 1.5 * wow_IQR\n",
    "        wow_lower = wow_Q1 - 1.5 * wow_IQR\n",
    "\n",
    "        for wow in list(wow_list):\n",
    "            if wow > wow_upper:\n",
    "                wow_list.remove(wow)\n",
    "                outliers_excluded += 1\n",
    "            elif wow < wow_lower:\n",
    "                wow_list.remove(wow)\n",
    "                outliers_excluded += 1\n",
    "                      \n",
    "    wow_output = sum(wow_list) / len(wow_list)     \n",
    "       \n",
    "    if holiday != \"Moving Holiday\":\n",
    "        dow_buckets = {}\n",
    "\n",
    "        for start in dow_per_dict:\n",
    "            for dow in dow_per_dict[start]:\n",
    "                if dow not in dow_buckets:\n",
    "                    dow_buckets[dow] = {}\n",
    "                dow_buckets[dow][start[-4:]] = dow_per_dict[start][dow]\n",
    "\n",
    "        for dow in dow_buckets:\n",
    "            dow_values = []\n",
    "            for year in dow_buckets[dow]:\n",
    "                dow_values.append(list(dow_buckets[dow].values()))\n",
    "\n",
    "            dow_Q1 = np.percentile(dow_values, 25)\n",
    "            dow_Q3 = np.percentile(dow_values, 75)\n",
    "            dow_IQR = dow_Q3 - dow_Q1\n",
    "            dow_upper = dow_Q3 + 1.5 * dow_IQR\n",
    "            dow_lower = dow_Q1 - 1.5 * dow_IQR\n",
    "\n",
    "            for start in list(dow_per_dict):\n",
    "                for dow2 in list(dow_per_dict[start]):\n",
    "                    if dow2 == dow and dow_per_dict[start][dow] >= dow_upper:\n",
    "                        del dow_per_dict[start][dow]\n",
    "                        outliers_excluded += 1\n",
    "                    elif dow2 == dow and dow_per_dict[start][dow] <= dow_lower:\n",
    "                        del dow_per_dict[start][dow]\n",
    "                        outliers_excluded += 1\n",
    "    \n",
    "    avg_dow_per = {\"Monday\": 0, \"Tuesday\": 0, \"Wednesday\": 0, \"Thursday\": 0, \"Friday\": 0, \"Saturday\": 0, \"Sunday\": 0}\n",
    "    for dow in avg_dow_per.keys():\n",
    "        count_dow_per = 0\n",
    "        total_dow_per = 0\n",
    "        for week in dow_per_dict:\n",
    "            for dow2 in dow_per_dict[week]:\n",
    "                if dow2 == dow:\n",
    "                    total_dow_per += dow_per_dict[week][dow]\n",
    "                    count_dow_per += 1\n",
    "        if count_dow_per == 0:\n",
    "            avg_dow_per[dow] = 0\n",
    "        else:\n",
    "            avg_dow_per[dow] = total_dow_per / count_dow_per\n",
    "            \n",
    "    dow_output = {}\n",
    "    \n",
    "    for dow in avg_dow_per:\n",
    "        if avg_dow_per[dow] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            dow_output[dow] = round(week_prior_total_volume * wow_output * avg_dow_per[dow])\n",
    "            \n",
    "    return {\"start_date\": start_date, \"unit\": unit, \"forecast\": dow_output, \"outliers_excluded\": outliers_excluded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d4e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_3(unit, start_date=start_of_week((object_to_str(today)),1)):\n",
    "    \"\"\"\n",
    "    Returns the total volume forecasted for the given unit for next week using method 3.\n",
    "    \"\"\"\n",
    "    print(\"Running Method 3 for week of \" + start_date)\n",
    "\n",
    "    week_to_compare_historical_volume = {} #Dictionary of volume by dow for each prior year matching the comparison week.\n",
    "    working_week_historical_volume = {} #Dictionary of volume by dow for each prior year matching the forecast week.\n",
    "    week_prior_total_volume = {} #Dictionary of volume by dow for the comparison week.\n",
    "    past_years_holiday_dow = {} #When there is a moving holiday, dictionary of the dow that holiday fell on each year\n",
    "    \n",
    "    working_year = start_date[-4:]\n",
    "    \n",
    "    \n",
    "    if start_date < start_of_week((object_to_str(today)),1):\n",
    "        week_to_compare = start_of_week(start_date, -1)\n",
    "    else:\n",
    "        week_to_compare = start_of_week(object_to_str(today), -1)\n",
    "        \n",
    "    comparison_year = week_to_compare[-4:]\n",
    "        \n",
    "        \n",
    "    comparison_week_matching_weeks_df = define_matching_weeks_df.copy()\n",
    "    for i in range(int((len(define_matching_weeks_df.columns) + 1)/2)):\n",
    "        comparison_week_matching_weeks_df.pop(comparison_week_matching_weeks_df.columns.values[0])\n",
    "    comparison_row = comparison_week_matching_weeks_df.index[comparison_week_matching_weeks_df[comparison_year + \" Date\"] == week_to_compare][0]\n",
    "    comparison_weeks = comparison_week_matching_weeks_df.values[comparison_row].tolist()\n",
    "    for week in list(comparison_weeks):\n",
    "        if int(week[-4:]) >= int(comparison_year):\n",
    "            comparison_weeks.remove(week)\n",
    "            \n",
    "    working_week_matching_weeks_df = define_matching_weeks_df.copy()\n",
    "    for i in range(int((len(define_matching_weeks_df.columns) + 1)/2)):\n",
    "        working_week_matching_weeks_df.pop(working_week_matching_weeks_df.columns.values[0])\n",
    "    working_row = working_week_matching_weeks_df.index[working_week_matching_weeks_df[working_year + \" Date\"] == start_date][0]\n",
    "    working_weeks = working_week_matching_weeks_df.values[working_row].tolist()\n",
    "    for week in list(working_weeks):\n",
    "        if int(week[-4:]) >= int(working_year):\n",
    "            working_weeks.remove(week)\n",
    "            \n",
    "            \n",
    "    ### IDENTIFYING HOLIDAY ###\n",
    "    week_df = define_matching_weeks_df[define_matching_weeks_df.isin([start_date]).any(axis=1)]\n",
    "    if week_df['Holiday'].isin(moving_holidays).any():\n",
    "        holiday = \"Moving Holiday\"\n",
    "    elif week_df['Holiday'].isin(static_holidays).any():\n",
    "        holiday = \"Static Holiday\"\n",
    "    else:\n",
    "        holiday = \"No Holiday\"\n",
    "    \n",
    "    \n",
    "    ### FILLING OUT LISTS AND DICTS ### \n",
    "    for week in comparison_weeks:\n",
    "        week_to_compare_historical_volume[week] = {}\n",
    "        current_week = week_volume(week, unit)\n",
    "        for day in current_week:\n",
    "            for dow in weekday_dict.keys():\n",
    "                if str_to_object(day).weekday() == dow:\n",
    "                    week_to_compare_historical_volume[week][weekday_dict[dow]] = current_week[day]\n",
    "\n",
    "    for week in working_weeks:\n",
    "        working_week_historical_volume[week] = {}\n",
    "        current_week = week_volume(week, unit)\n",
    "        for day in current_week:\n",
    "            for dow in weekday_dict.keys():\n",
    "                if str_to_object(day).weekday() == dow:\n",
    "                    working_week_historical_volume[week][weekday_dict[dow]] = current_week[day]\n",
    "\n",
    "    prior_week = week_volume(week_to_compare, unit)\n",
    "    for day in prior_week:\n",
    "        for dow in weekday_dict.keys():\n",
    "            if str_to_object(day).weekday() == dow:\n",
    "                week_prior_total_volume[weekday_dict[dow]] = prior_week[day]\n",
    "                    \n",
    "                    \n",
    "     ### DELETING KEYS IN DICTS WHERE THE VALUE IS 0 ###               \n",
    "    for dow in list(week_prior_total_volume):\n",
    "        if week_prior_total_volume[dow] == 0:\n",
    "            del week_prior_total_volume[dow]\n",
    "            \n",
    "    for week in list(week_to_compare_historical_volume):\n",
    "        for dow in list(week_to_compare_historical_volume[week]):\n",
    "            if week_to_compare_historical_volume[week][dow] == 0:\n",
    "                del week_to_compare_historical_volume[week][dow]\n",
    "                \n",
    "    for week in list(working_week_historical_volume):\n",
    "        for dow in list(working_week_historical_volume[week]):\n",
    "            if working_week_historical_volume[week][dow] == 0:\n",
    "                del working_week_historical_volume[week][dow]\n",
    "\n",
    "\n",
    "    ### REMOVING OUTLIERS AND CALCULATING END VALUES ###            \n",
    "    dow_buckets_week_to_compare_historical_volume = {}\n",
    "    for start in week_to_compare_historical_volume:\n",
    "        for dow in week_to_compare_historical_volume[start]:\n",
    "            if dow not in dow_buckets_week_to_compare_historical_volume:\n",
    "                dow_buckets_week_to_compare_historical_volume[dow] = {}\n",
    "            dow_buckets_week_to_compare_historical_volume[dow][start[-4:]] = week_to_compare_historical_volume[start][dow]\n",
    "            \n",
    "    dow_buckets_working_week_historical_volume = {}\n",
    "    for start in working_week_historical_volume:\n",
    "        for dow in working_week_historical_volume[start]:\n",
    "            if dow not in dow_buckets_working_week_historical_volume:\n",
    "                dow_buckets_working_week_historical_volume[dow] = {}\n",
    "            dow_buckets_working_week_historical_volume[dow][start[-4:]] = working_week_historical_volume[start][dow]\n",
    "            \n",
    "    per_change = {dow: {year: dow_buckets_working_week_historical_volume[dow][year]/dow_buckets_week_to_compare_historical_volume[dow][year] for year in dow_buckets_working_week_historical_volume[dow].keys() & dow_buckets_week_to_compare_historical_volume[dow]} for dow in dow_buckets_working_week_historical_volume.keys() & dow_buckets_week_to_compare_historical_volume}\n",
    "    for dow in list(per_change):\n",
    "        check_empty = not bool(per_change[dow])\n",
    "        if check_empty == True:\n",
    "            del per_change[dow]\n",
    "            \n",
    "    if holiday == \"Moving Holiday\":\n",
    "        holiday_name = week_df['Holiday'].item()\n",
    "        for date, name in sorted(holidays.US(years=int(working_year)).items()):\n",
    "            if name == holiday_name:\n",
    "                holiday_date = date\n",
    "            else:\n",
    "                continue\n",
    "        for dow in per_change:\n",
    "            for year in per_change[dow]:\n",
    "                past_years_holiday_dow[year] = str_to_object(object_to_str(holiday_date)[:-4]+year).weekday()\n",
    "        for dow in per_change:\n",
    "            for year in list(per_change[dow]):\n",
    "                if past_years_holiday_dow[year] != holiday_date.weekday():\n",
    "                    del per_change[dow][year]\n",
    "\n",
    "    outliers_excluded = 0\n",
    "    \n",
    "    if holiday != \"Moving Holiday\":\n",
    "\n",
    "        for dow in per_change:\n",
    "            dod_values = []\n",
    "            for year in dow_buckets_working_week_historical_volume[dow]:\n",
    "                dod_values.append(list(per_change[dow].values()))\n",
    "\n",
    "            dod_Q1 = np.percentile(dod_values, 25)\n",
    "            dod_Q3 = np.percentile(dod_values, 75)\n",
    "            dod_IQR = dod_Q3 - dod_Q1\n",
    "            dod_upper = dod_Q3 + 1.5 * dod_IQR\n",
    "            dod_lower = dod_Q1 - 1.5 * dod_IQR\n",
    "\n",
    "            for year in list(per_change[dow]):\n",
    "                if per_change[dow][year] > dod_upper:\n",
    "                    del per_change[dow][year]\n",
    "                    outliers_excluded += 1\n",
    "                elif per_change[dow][year] < dod_lower:\n",
    "                    del per_change[dow][year]\n",
    "                    outliers_excluded += 1\n",
    "\n",
    "    dod_output = {}\n",
    "    for dow in list(per_change):\n",
    "        total = 0\n",
    "        count = 0\n",
    "        if len(per_change[dow]) == 0:\n",
    "            del per_change[dow]\n",
    "        else:\n",
    "            for year in per_change[dow]:\n",
    "                total += per_change[dow][year]\n",
    "                count += 1\n",
    "            dod_output[dow] = total / count\n",
    "        \n",
    "    forecast = {}\n",
    "    for dow in week_prior_total_volume:\n",
    "        if dow not in dod_output:\n",
    "            continue\n",
    "        forecast[dow] = round(week_prior_total_volume[dow] * dod_output[dow])\n",
    "    \n",
    "    return {\"start_date\": start_date, \"unit\": unit, \"forecast\": forecast, \"outliers_excluded\": outliers_excluded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45022405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_4(unit, start_date=start_of_week((object_to_str(today)),1)):\n",
    "    \"\"\"\n",
    "    Returns the total volume forecasted for the given unit for next week using method 4.\n",
    "    \"\"\"\n",
    "    print(\"Running Method 4 for week of \" + start_date)\n",
    "\n",
    "    yearly_volume_dict = {} #Dictionary of each year's total volume.\n",
    "    per_last_4_matching_volume = {} #Dictionary of the percentage of volume received in the last 4 comparison weeks of prior years.\n",
    "    per_working_matching_volume = {} #Dictionary of the percentage of volume received in the forecast week of prior years.\n",
    "    dow_per_dict = {} #Dictionary of the dow % for each day of week for the matching weeks of each year.\n",
    "    past_years_holiday_dow = {} #When there is a moving holiday, dictionary of the dow that holiday fell on each year\n",
    "\n",
    "    \n",
    "    working_year = start_date[-4:]\n",
    "    \n",
    "    if start_date < start_of_week((object_to_str(today)),1):\n",
    "        week_to_compare = start_of_week(start_date, -1)\n",
    "    else:\n",
    "        week_to_compare = start_of_week(object_to_str(today), -1)\n",
    "        \n",
    "    comparison_year = week_to_compare[-4:]\n",
    "    \n",
    "    last_4_current_year_volume = sum(week_volume(week_to_compare, unit).values()) + sum(week_volume(start_of_week(week_to_compare), unit).values())\\\n",
    "    + sum(week_volume(start_of_week(week_to_compare, -1), unit).values()) + sum(week_volume(start_of_week(week_to_compare, -2), unit).values())\n",
    "    \n",
    "    \n",
    "\n",
    "    comparison_week_matching_weeks_df = define_matching_weeks_df.copy()\n",
    "    for i in range(int((len(define_matching_weeks_df.columns) + 1)/2)):\n",
    "        comparison_week_matching_weeks_df.pop(comparison_week_matching_weeks_df.columns.values[0])\n",
    "    comparison_row = comparison_week_matching_weeks_df.index[comparison_week_matching_weeks_df[comparison_year + \" Date\"] == week_to_compare][0]\n",
    "    comparison_weeks = comparison_week_matching_weeks_df.values[comparison_row].tolist()\n",
    "    for week in list(comparison_weeks):\n",
    "        if int(week[-4:]) >= int(comparison_year):\n",
    "            comparison_weeks.remove(week)\n",
    "            \n",
    "    working_week_matching_weeks_df = define_matching_weeks_df.copy()\n",
    "    for i in range(int((len(define_matching_weeks_df.columns) + 1)/2)):\n",
    "        working_week_matching_weeks_df.pop(working_week_matching_weeks_df.columns.values[0])\n",
    "    working_row = working_week_matching_weeks_df.index[working_week_matching_weeks_df[working_year + \" Date\"] == start_date][0]\n",
    "    working_weeks = working_week_matching_weeks_df.values[working_row].tolist()\n",
    "    for week in list(working_weeks):\n",
    "        if int(week[-4:]) >= int(working_year):\n",
    "            working_weeks.remove(week)\n",
    "            \n",
    "    \n",
    "    ### IDENTIFYING HOLIDAY ###\n",
    "    week_df = define_matching_weeks_df[define_matching_weeks_df.isin([start_date]).any(axis=1)]\n",
    "    if week_df['Holiday'].isin(moving_holidays).any():\n",
    "        holiday = \"Moving Holiday\"\n",
    "    elif week_df['Holiday'].isin(static_holidays).any():\n",
    "        holiday = \"Static Holiday\"\n",
    "    else:\n",
    "        holiday = \"No Holiday\"\n",
    "            \n",
    "\n",
    "    ### FILLING OUT LISTS AND DICTS ### \n",
    "    for year in range(2012, int(object_to_str(today)[-4:])+1):\n",
    "        yearly_volume_dict[year] = yearly_volume(year, unit)\n",
    "\n",
    "    for year in list(yearly_volume_dict):\n",
    "        if yearly_volume_dict[year] == 0:\n",
    "            del yearly_volume_dict[year]\n",
    "    \n",
    "    for week in comparison_weeks:\n",
    "        year = week[-4:]\n",
    "        if int(year) not in yearly_volume_dict:\n",
    "            continue\n",
    "        per_last_4_matching_volume[week[-4:]] = (sum(week_volume(week, unit).values()) / yearly_volume_dict[int(week[-4:])]) + (sum(week_volume(start_of_week(week), unit).values()) / yearly_volume_dict[int(week[-4:])])\\\n",
    "        + (sum(week_volume(start_of_week(week, -1), unit).values()) / yearly_volume_dict[int(week[-4:])]) + (sum(week_volume(start_of_week(week, -2), unit).values()) / yearly_volume_dict[int(week[-4:])])\n",
    "        \n",
    "    if holiday == \"Moving Holiday\":\n",
    "        holiday_name = week_df['Holiday'].item()\n",
    "        for date, name in sorted(holidays.US(years=int(working_year)).items()):\n",
    "            if name == holiday_name:\n",
    "                holiday_date = date\n",
    "            else:\n",
    "                continue\n",
    "        for idx in range(len(working_weeks)):\n",
    "            past_years_holiday_dow[working_weeks[idx][-4:]] = str_to_object(object_to_str(holiday_date)[:-4]+working_weeks[idx][-4:]).weekday()\n",
    "        for week in list(working_weeks):\n",
    "            if past_years_holiday_dow[week[-4:]] != holiday_date.weekday():\n",
    "                working_weeks.remove(week)\n",
    "\n",
    "    for week in working_weeks:\n",
    "        year = week[-4:]\n",
    "        if int(year) not in yearly_volume_dict:\n",
    "            continue\n",
    "        per_working_matching_volume[week[-4:]] = (sum(week_volume(week, unit).values()) / yearly_volume_dict[int(week[-4:])]) + (sum(week_volume(start_of_week(week), unit).values()) / yearly_volume_dict[int(week[-4:])])\\\n",
    "        + (sum(week_volume(start_of_week(week, -1), unit).values()) / yearly_volume_dict[int(week[-4:])]) + (sum(week_volume(start_of_week(week, -2), unit).values()) / yearly_volume_dict[int(week[-4:])])\n",
    "    \n",
    "    for start in working_weeks:\n",
    "        year_current = start[-4:]\n",
    "        if int(year_current) >= int(working_year):\n",
    "            continue\n",
    "        if int(year_current) not in yearly_volume_dict or yearly_volume_dict[int(year_current)] == 0:\n",
    "            continue\n",
    "        if year_current not in dow_per_dict:\n",
    "            dow_per_dict[year_current] = {}\n",
    "        for dow in range(0, 7):\n",
    "            date_current = object_to_str(str_to_object(start) + dt.timedelta(days=dow + 1))\n",
    "            dow_current = weekday_dict[dow]\n",
    "            dow_per_dict[year_current][dow_current] = day_volume(date_current, unit) / sum(week_volume(start, unit).values())\n",
    "    \n",
    "    \n",
    "    ### REMOVING OUTLIERS AND CALCULATING END VALUES ### \n",
    "    outliers_excluded = 0\n",
    "\n",
    "    for year in list(per_last_4_matching_volume):\n",
    "        year_values = list(per_last_4_matching_volume.values())\n",
    "\n",
    "        year_Q1 = np.percentile(year_values, 25)\n",
    "        year_Q3 = np.percentile(year_values, 75)\n",
    "        year_IQR = year_Q3 - year_Q1\n",
    "        year_upper = year_Q3 + 1.5 * year_IQR\n",
    "        year_lower = year_Q1 - 1.5 * year_IQR\n",
    "\n",
    "        for year in list(per_last_4_matching_volume):\n",
    "            if per_last_4_matching_volume[year] > year_upper:\n",
    "                del per_last_4_matching_volume[year]\n",
    "                outliers_excluded += 1\n",
    "            elif per_last_4_matching_volume[year] < year_lower:\n",
    "                del per_last_4_matching_volume[year]\n",
    "                outliers_excluded += 1\n",
    "    \n",
    "    avg_per_last_4 = sum(per_last_4_matching_volume.values()) / len(per_last_4_matching_volume) / 4\n",
    "        \n",
    "\n",
    "    if holiday != \"Moving Holiday\":\n",
    "        \n",
    "        for year in list(per_working_matching_volume):\n",
    "            year_values = list(per_working_matching_volume.values())\n",
    "\n",
    "            year_Q1 = np.percentile(year_values, 25)\n",
    "            year_Q3 = np.percentile(year_values, 75)\n",
    "            year_IQR = year_Q3 - year_Q1\n",
    "            year_upper = year_Q3 + 1.5 * year_IQR\n",
    "            year_lower = year_Q1 - 1.5 * year_IQR\n",
    "\n",
    "            for year in list(per_working_matching_volume):\n",
    "                if per_working_matching_volume[year] > year_upper:\n",
    "                    del per_working_matching_volume[year]\n",
    "                    outliers_excluded += 1\n",
    "                elif per_working_matching_volume[year] < year_lower:\n",
    "                    del per_working_matching_volume[year]\n",
    "                    outliers_excluded += 1\n",
    "                \n",
    "    avg_per_working = sum(per_working_matching_volume.values()) / len(per_working_matching_volume)\n",
    "    \n",
    "    per_change = (avg_per_working - avg_per_last_4)\n",
    "    \n",
    "    total_week_forecast = last_4_current_year_volume * (1 + per_change) / 4\n",
    "\n",
    "        \n",
    "    dow_buckets = {}\n",
    "    \n",
    "    for week in dow_per_dict:\n",
    "        for dow in dow_per_dict[week]:\n",
    "            if dow not in dow_buckets:\n",
    "                dow_buckets[dow] = []\n",
    "            dow_buckets[dow].append(dow_per_dict[week][dow])\n",
    "    \n",
    "    if holiday != \"Moving Holiday\":\n",
    "\n",
    "        for dow in dow_buckets:\n",
    "            dow_Q1 = np.percentile(dow_buckets[dow], 25)\n",
    "            dow_Q3 = np.percentile(dow_buckets[dow], 75)\n",
    "            dow_IQR = dow_Q3 - dow_Q1\n",
    "            dow_upper = dow_Q3 + 1.5 * dow_IQR\n",
    "            dow_lower = dow_Q1 - 1.5 * dow_IQR\n",
    "\n",
    "            for value in list(dow_buckets[dow]):\n",
    "                if value > dow_upper:\n",
    "                    dow_buckets[dow].remove(value)\n",
    "                    outliers_excluded += 1\n",
    "                elif value < dow_lower:\n",
    "                    dow_buckets[dow].remove(value)\n",
    "                    outliers_excluded += 1\n",
    "                \n",
    "    dow_average = {}\n",
    "    \n",
    "    for dow in dow_buckets:\n",
    "        dow_average[dow] = sum(dow_buckets[dow]) / len(dow_buckets[dow])\n",
    "        \n",
    "    dow_output = {}\n",
    "    \n",
    "    for dow in dow_average:\n",
    "        if dow_average[dow] == 0:\n",
    "            continue\n",
    "        dow_output[dow] = round(dow_average[dow] * total_week_forecast)\n",
    "\n",
    "    return {\"start_date\": start_date, \"unit\": unit, \"forecast\": dow_output, \"outliers_excluded\": outliers_excluded}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f3f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(function):\n",
    "    \"\"\"\n",
    "    Returns the accuracy of a forecast.\n",
    "    \"\"\"\n",
    "    unit = function[\"unit\"]\n",
    "    start_date = function[\"start_date\"]\n",
    "    forecast = function[\"forecast\"]\n",
    "    actual_volume = {}\n",
    "    \n",
    "    for dow in forecast:\n",
    "        if dow == \"Sunday\":\n",
    "            actual_volume[start_date] = day_volume(start_date)\n",
    "        elif dow == \"Monday\":\n",
    "            actual_volume[\"Monday\"] = day_volume(object_to_str(str_to_object(start_date) + dt.timedelta(days=1)), unit)\n",
    "        elif dow == \"Tuesday\":\n",
    "            actual_volume[\"Tuesday\"] = day_volume(object_to_str(str_to_object(start_date) + dt.timedelta(days=2)), unit)\n",
    "        elif dow == \"Wednesday\":\n",
    "            actual_volume[\"Wednesday\"] = day_volume(object_to_str(str_to_object(start_date) + dt.timedelta(days=3)), unit)\n",
    "        elif dow == \"Thursday\":\n",
    "            actual_volume[\"Thursday\"] = day_volume(object_to_str(str_to_object(start_date) + dt.timedelta(days=4)), unit)\n",
    "        elif dow == \"Friday\":\n",
    "            actual_volume[\"Friday\"] = day_volume(object_to_str(str_to_object(start_date) + dt.timedelta(days=5)), unit)\n",
    "        elif dow == \"Saturday\":\n",
    "            actual_volume[\"Saturday\"] = day_volume(object_to_str(str_to_object(start_date) + dt.timedelta(days=6)), unit)\n",
    "        \n",
    "                \n",
    "    accuracy_by_day = copy.deepcopy(actual_volume)\n",
    "    \n",
    "    for dow in accuracy_by_day:\n",
    "        if forecast[dow] == 0:\n",
    "            continue\n",
    "        accuracy_by_day[dow] = abs((actual_volume[dow] - forecast[dow]) / forecast[dow])\n",
    "        \n",
    "    week_accuracy = sum(accuracy_by_day.values()) / len(accuracy_by_day)\n",
    "    \n",
    "    return {\"week_accuracy\": week_accuracy, \"accuracy_by_day\": accuracy_by_day}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb5ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_accurate(unit):\n",
    "    \"\"\"\n",
    "    Returns the most accurate forecasting method over the past 4 weeks.\n",
    "    \"\"\"\n",
    "    method_1_accuracy = (accuracy(method_1(unit, start_of_week(object_to_str(today), -4)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_1(unit, start_of_week(object_to_str(today), -3)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_1(unit, start_of_week(object_to_str(today), -2)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_1(unit, start_of_week(object_to_str(today), -1)))[\"week_accuracy\"]) / 4\n",
    "\n",
    "    method_2_accuracy = (accuracy(method_2(unit, start_of_week(object_to_str(today), -4)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_2(unit, start_of_week(object_to_str(today), -3)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_2(unit, start_of_week(object_to_str(today), -2)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_2(unit, start_of_week(object_to_str(today), -1)))[\"week_accuracy\"]) / 4\n",
    "    \n",
    "    method_3_accuracy = (accuracy(method_3(unit, start_of_week(object_to_str(today), -4)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_3(unit, start_of_week(object_to_str(today), -3)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_3(unit, start_of_week(object_to_str(today), -2)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_3(unit, start_of_week(object_to_str(today), -1)))[\"week_accuracy\"]) / 4\n",
    "    \n",
    "    method_4_accuracy = (accuracy(method_4(unit, start_of_week(object_to_str(today), -4)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_4(unit, start_of_week(object_to_str(today), -3)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_4(unit, start_of_week(object_to_str(today), -2)))[\"week_accuracy\"] + \\\n",
    "                         accuracy(method_4(unit, start_of_week(object_to_str(today), -1)))[\"week_accuracy\"]) / 4\n",
    "    \n",
    "    if method_1_accuracy < method_2_accuracy and method_1_accuracy < method_3_accuracy and method_1_accuracy < method_4_accuracy:\n",
    "        best_accuracy = method_1_accuracy\n",
    "        most_accurate_method = 1\n",
    "    elif method_2_accuracy <= method_1_accuracy and method_2_accuracy < method_3_accuracy and method_2_accuracy < method_4_accuracy:\n",
    "        best_accuracy = method_2_accuracy\n",
    "        most_accurate_method = 2\n",
    "    elif method_3_accuracy <= method_1_accuracy and method_3_accuracy <= method_2_accuracy and method_3_accuracy < method_4_accuracy:\n",
    "        best_accuracy = method_3_accuracy\n",
    "        most_accurate_method = 3\n",
    "    elif method_4_accuracy <= method_1_accuracy and method_4_accuracy <= method_2_accuracy and method_4_accuracy <= method_3_accuracy:\n",
    "        best_accuracy = method_4_accuracy\n",
    "        most_accurate_method = 4\n",
    "    else:\n",
    "        return \"something's gone horribly wrong\"\n",
    "        \n",
    "    best_accuracy = round((1-best_accuracy) * 100, 2)\n",
    "    \n",
    "    return {\"most_accurate_method\": most_accurate_method, \"accuracy\": best_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30d528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tactical_volume_forecast_v1(unit):\n",
    "    \"\"\"\n",
    "    Returns the tactical (next 3 weeks) volume forecast using the method that has been the most accurate recently.\n",
    "    \"\"\"\n",
    "    \n",
    "    final_answer = most_accurate(unit)\n",
    "    method = final_answer[\"most_accurate_method\"]\n",
    "    accuracy = final_answer[\"accuracy\"]\n",
    "    \n",
    "    if method == 1:\n",
    "        print(\"\\n*** Method 1 has been \" + str(accuracy) + \"% accurate over the past four weeks. ***\\n\")\n",
    "        return {\"unit\":unit,\"method\":method, \"accuracy\":accuracy, start_of_week(object_to_str(today), 1):method_1(unit, start_of_week(object_to_str(today), 1)), start_of_week(object_to_str(today), 2):method_1(unit, start_of_week(object_to_str(today), 2)), start_of_week(object_to_str(today), 3):method_1(unit, start_of_week(object_to_str(today), 3))}\n",
    "    \n",
    "    elif method == 2:\n",
    "        print(\"\\n*** Method 2 has been \" + str(accuracy) + \"% accurate over the past four weeks. ***\\n\")\n",
    "        return {\"unit\":unit,\"method\":method, \"accuracy\":accuracy, start_of_week(object_to_str(today), 1):method_2(unit, start_of_week(object_to_str(today), 1)), start_of_week(object_to_str(today), 2):method_2(unit, start_of_week(object_to_str(today), 2)), start_of_week(object_to_str(today), 3):method_2(unit, start_of_week(object_to_str(today), 3))}\n",
    "    \n",
    "    elif method == 3:\n",
    "        print(\"\\n*** Method 3 has been \" + str(accuracy) + \"% accurate over the past four weeks. ***\\n\")\n",
    "        return {\"unit\":unit,\"method\":method, \"accuracy\":accuracy, start_of_week(object_to_str(today), 1):method_3(unit, start_of_week(object_to_str(today), 1)), start_of_week(object_to_str(today), 2):method_3(unit, start_of_week(object_to_str(today), 2)), start_of_week(object_to_str(today), 3):method_3(unit, start_of_week(object_to_str(today), 3))}\n",
    "    \n",
    "    elif method == 4:\n",
    "        print(\"\\n*** Method 4 has been \" + str(accuracy) + \"% accurate over the past four weeks. ***\\n\")\n",
    "        return {\"unit\":unit,\"method\":method, \"accuracy\":accuracy, start_of_week(object_to_str(today), 1):method_4(unit, start_of_week(object_to_str(today), 1)), start_of_week(object_to_str(today), 2):method_4(unit, start_of_week(object_to_str(today), 2)), start_of_week(object_to_str(today), 3):method_4(unit, start_of_week(object_to_str(today), 3))}\n",
    "    \n",
    "    else:\n",
    "        return \"something's gone horribly wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b3635d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tactical_volume_forecast_v2(unit):\n",
    "    \"\"\"\n",
    "    Returns the tactical (next 3 weeks) volume forecast using an elastic net model.\n",
    "    \"\"\"\n",
    "    forecast_week = object_to_str(today)\n",
    "    \n",
    "    accuracy_dict = {}\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    \n",
    "    current_week = -4\n",
    "    \n",
    "    while current_week < 0:\n",
    "        \n",
    "        if current_week == -4:\n",
    "            accuracy_dict[1] = {}\n",
    "            accuracy_dict[2] = {}\n",
    "            accuracy_dict[3] = {}\n",
    "            accuracy_dict[4] = {}\n",
    "        \n",
    "        current_method = 4\n",
    "    \n",
    "        while current_method > 0:\n",
    "            \n",
    "\n",
    "            if current_method == 1:\n",
    "                temp_forecast_dict = method_1(unit, start_of_week(forecast_week, current_week))\n",
    "            elif current_method == 2:\n",
    "                temp_forecast_dict = method_2(unit, start_of_week(forecast_week, current_week))\n",
    "            elif current_method == 3:\n",
    "                temp_forecast_dict = method_3(unit, start_of_week(forecast_week, current_week))\n",
    "            elif current_method == 4:\n",
    "                temp_forecast_dict = method_4(unit, start_of_week(forecast_week, current_week))\n",
    "\n",
    "            for dow in temp_forecast_dict[\"forecast\"]:\n",
    "                if dow == \"Monday\":\n",
    "                    accuracy_dict[current_method][object_to_str(str_to_object(temp_forecast_dict[\"start_date\"]) + dt.timedelta(days=1))] = int(temp_forecast_dict[\"forecast\"][\"Monday\"])\n",
    "                elif dow == \"Tuesday\":\n",
    "                    accuracy_dict[current_method][object_to_str(str_to_object(temp_forecast_dict[\"start_date\"]) + dt.timedelta(days=2))] = int(temp_forecast_dict[\"forecast\"][\"Tuesday\"])\n",
    "                elif dow == \"Wednesday\":\n",
    "                    accuracy_dict[current_method][object_to_str(str_to_object(temp_forecast_dict[\"start_date\"]) + dt.timedelta(days=3))] = int(temp_forecast_dict[\"forecast\"][\"Wednesday\"])\n",
    "                elif dow == \"Thursday\":\n",
    "                    accuracy_dict[current_method][object_to_str(str_to_object(temp_forecast_dict[\"start_date\"]) + dt.timedelta(days=4))] = int(temp_forecast_dict[\"forecast\"][\"Thursday\"])\n",
    "                elif dow == \"Friday\":\n",
    "                    accuracy_dict[current_method][object_to_str(str_to_object(temp_forecast_dict[\"start_date\"]) + dt.timedelta(days=5))] = int(temp_forecast_dict[\"forecast\"][\"Friday\"])\n",
    "                elif dow == \"Saturday\":\n",
    "                    accuracy_dict[current_method][object_to_str(str_to_object(temp_forecast_dict[\"start_date\"]) + dt.timedelta(days=6))] = int(temp_forecast_dict[\"forecast\"][\"Saturday\"])\n",
    "                elif dow == \"Saturday\":\n",
    "                    accuracy_dict[current_method][object_to_str(str_to_object(temp_forecast_dict[\"start_date\"]) + dt.timedelta(days=7))] = int(temp_forecast_dict[\"forecast\"][\"Sunday\"])\n",
    "\n",
    "            current_method = current_method - 1\n",
    "        \n",
    "        current_week = current_week + 1\n",
    "    \n",
    "    df = pd.DataFrame(accuracy_dict)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    actuals_dict = {}\n",
    "    \n",
    "    for date in accuracy_dict[1]:\n",
    "        actuals_dict[date] = day_volume(date, unit)\n",
    "        \n",
    "    df[\"Actual\"] = pd.Series(actuals_dict)\n",
    "    \n",
    "    X = df[[1,2,3,4]]\n",
    "    y = df['Actual']\n",
    "    \n",
    "    elastic = ElasticNet(random_state=0)\n",
    "    elastic.fit(X,y)\n",
    "    \n",
    "    regr = LinearRegression.fit(X, y)\n",
    "\n",
    "    print(\"Forecasting...\")\n",
    "    \n",
    "    week1method1 = method_1(unit, start_of_week(forecast_week, 1))\n",
    "    week1method2 = method_2(unit, start_of_week(forecast_week, 1))\n",
    "    week1method3 = method_3(unit, start_of_week(forecast_week, 1))\n",
    "    week1method4 = method_4(unit, start_of_week(forecast_week, 1))\n",
    "    week2method1 = method_1(unit, start_of_week(forecast_week, 2))\n",
    "    week2method2 = method_2(unit, start_of_week(forecast_week, 2))\n",
    "    week2method3 = method_3(unit, start_of_week(forecast_week, 2))\n",
    "    week2method4 = method_4(unit, start_of_week(forecast_week, 2))\n",
    "    week3method1 = method_1(unit, start_of_week(forecast_week, 3))\n",
    "    print(week3method1[\"forecast\"])\n",
    "    week3method2 = method_2(unit, start_of_week(forecast_week, 3))\n",
    "    print(week3method1[\"forecast\"])\n",
    "    week3method3 = method_3(unit, start_of_week(forecast_week, 3))\n",
    "    print(week3method1[\"forecast\"])\n",
    "    week3method4 = method_4(unit, start_of_week(forecast_week, 3))\n",
    "    print(week3method1[\"forecast\"])\n",
    "    \n",
    "    for day in week1method1[\"forecast\"]:\n",
    "        if day not in week1method3:\n",
    "            week1method3[\"forecast\"][day] = week1method2[\"forecast\"][day]\n",
    "    for day in week2method1[\"forecast\"]:\n",
    "        if day not in week2method3:\n",
    "            week2method3[\"forecast\"][day] = week2method2[\"forecast\"][day]\n",
    "    for day in week3method1[\"forecast\"]:\n",
    "        if day not in week3method3:\n",
    "            week3method3[\"forecast\"][day] = week3method2[\"forecast\"][day]\n",
    "    \n",
    "\n",
    "\n",
    "    final_answer = {\"unit\": unit, start_of_week(forecast_week, 1):{}, start_of_week(forecast_week, 2):{}, start_of_week(forecast_week, 3):{}}\n",
    "\n",
    "    #WEEK 1 FINAL ANSWER\n",
    "    week_df = define_matching_weeks_df[define_matching_weeks_df.isin([start_of_week(forecast_week,1)]).any(axis=1)]\n",
    "    if week_df['Holiday'].isin(moving_holidays).any():\n",
    "        holiday = \"Moving Holiday\"\n",
    "    elif week_df['Holiday'].isin(static_holidays).any():\n",
    "        holiday = \"Static Holiday\"\n",
    "    else:\n",
    "        holiday = \"No Holiday\"\n",
    "    print(holiday)\n",
    "    for day in week1method1[\"forecast\"]:\n",
    "        predict = elastic.predict([[week1method1[\"forecast\"][day],week1method2[\"forecast\"][day],week1method3[\"forecast\"][day],week1method4[\"forecast\"][day]]])\n",
    "        final_answer[start_of_week(forecast_week, 1)][day] = int(predict.item())\n",
    "\n",
    "    #WEEK 2 FINAL ANSWER\n",
    "    week_df = define_matching_weeks_df[define_matching_weeks_df.isin([start_of_week(forecast_week,2)]).any(axis=1)]\n",
    "    if week_df['Holiday'].isin(moving_holidays).any():\n",
    "        holiday = \"Moving Holiday\"\n",
    "    elif week_df['Holiday'].isin(static_holidays).any():\n",
    "        holiday = \"Static Holiday\"\n",
    "    else:\n",
    "        holiday = \"No Holiday\"\n",
    "    print(holiday)\n",
    "    for day in week2method1[\"forecast\"]:\n",
    "        predict = elastic.predict([[week2method1[\"forecast\"][day],week2method2[\"forecast\"][day],week2method3[\"forecast\"][day],week2method4[\"forecast\"][day]]])  \n",
    "        final_answer[start_of_week(forecast_week, 2)][day] = int(predict.item())\n",
    "\n",
    "    #WEEK 3 FINAL ANSWER\n",
    "    week_df = define_matching_weeks_df[define_matching_weeks_df.isin([start_of_week(forecast_week,3)]).any(axis=1)]\n",
    "    if week_df['Holiday'].isin(moving_holidays).any():\n",
    "        holiday = \"Moving Holiday\"\n",
    "    elif week_df['Holiday'].isin(static_holidays).any():\n",
    "        holiday = \"Static Holiday\"\n",
    "    else:\n",
    "        holiday = \"No Holiday\"\n",
    "    print(holiday)\n",
    "    if week3method1 == week3method2 == week3method3 == week3method4:\n",
    "        for day in week3method1[\"forecast\"]:\n",
    "            predict = regr.predict([[week3method1[\"forecast\"][day],week3method2[\"forecast\"][day],week3method3[\"forecast\"][day],week3method4[\"forecast\"][day]]])\n",
    "            final_answer[start_of_week(forecast_week, 3)][day] = int(predict.item())\n",
    "    else:\n",
    "        for day in week3method1[\"forecast\"]:\n",
    "            predict = elastic.predict([[week3method1[\"forecast\"][day],week3method2[\"forecast\"][day],week3method3[\"forecast\"][day],week3method4[\"forecast\"][day]]])\n",
    "            final_answer[start_of_week(forecast_week, 3)][day] = int(predict.item())\n",
    "\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3837af1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Running Method 4 for week of 09/17/2023\n",
      "Running Method 3 for week of 09/17/2023\n",
      "Running Method 2 for week of 09/17/2023\n",
      "Running Method 1 for week of 09/17/2023\n",
      "Running Method 4 for week of 09/24/2023\n",
      "Running Method 3 for week of 09/24/2023\n",
      "Running Method 2 for week of 09/24/2023\n",
      "Running Method 1 for week of 09/24/2023\n",
      "Running Method 4 for week of 10/01/2023\n",
      "Running Method 3 for week of 10/01/2023\n",
      "Running Method 2 for week of 10/01/2023\n",
      "Running Method 1 for week of 10/01/2023\n",
      "Running Method 4 for week of 10/08/2023\n",
      "Running Method 3 for week of 10/08/2023\n",
      "Running Method 2 for week of 10/08/2023\n",
      "Running Method 1 for week of 10/08/2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sstein13\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.269e+04, tolerance: 3.344e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting...\n",
      "Running Method 1 for week of 10/22/2023\n",
      "Running Method 2 for week of 10/22/2023\n",
      "Running Method 3 for week of 10/22/2023\n",
      "Running Method 4 for week of 10/22/2023\n",
      "Running Method 1 for week of 10/29/2023\n",
      "Running Method 2 for week of 10/29/2023\n",
      "Running Method 3 for week of 10/29/2023\n",
      "Running Method 4 for week of 10/29/2023\n",
      "Running Method 1 for week of 11/05/2023\n",
      "{'Monday': 1593, 'Tuesday': 1297, 'Wednesday': 1193, 'Thursday': 1177, 'Friday': 1150, 'Saturday': 404}\n",
      "Running Method 2 for week of 11/05/2023\n",
      "{'Monday': 1593, 'Tuesday': 1297, 'Wednesday': 1193, 'Thursday': 1177, 'Friday': 1150, 'Saturday': 404}\n",
      "Running Method 3 for week of 11/05/2023\n",
      "{'Monday': 1593, 'Tuesday': 1297, 'Wednesday': 1193, 'Thursday': 1177, 'Friday': 1150, 'Saturday': 404}\n",
      "Running Method 4 for week of 11/05/2023\n",
      "{'Monday': 1593, 'Tuesday': 1297, 'Wednesday': 1193, 'Thursday': 1177, 'Friday': 1150, 'Saturday': 404}\n",
      "No Holiday\n",
      "No Holiday\n",
      "Moving Holiday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'unit': 'Sales',\n",
       " '10/22/2023': {'Monday': 1556,\n",
       "  'Tuesday': 1305,\n",
       "  'Wednesday': 1192,\n",
       "  'Thursday': 1108,\n",
       "  'Friday': 1089,\n",
       "  'Saturday': 423},\n",
       " '10/29/2023': {'Monday': 1499,\n",
       "  'Tuesday': 1284,\n",
       "  'Wednesday': 1197,\n",
       "  'Thursday': 1140,\n",
       "  'Friday': 1101,\n",
       "  'Saturday': 449},\n",
       " '11/05/2023': {'Monday': 1619,\n",
       "  'Tuesday': 1317,\n",
       "  'Wednesday': 1211,\n",
       "  'Thursday': 1195,\n",
       "  'Friday': 1167,\n",
       "  'Saturday': 407}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tactical_volume_forecast_v2(\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d899f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
